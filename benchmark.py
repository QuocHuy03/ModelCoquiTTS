#!/usr/bin/env python3
"""
Voice Cloning Performance Benchmark
Test tá»‘c Ä‘á»™ voice cloning vá»›i cÃ¡c settings khÃ¡c nhau
"""

import os
import time
import torch
from voice_cloner import VoiceCloner

def benchmark_voice_cloning():
    """Benchmark voice cloning performance"""
    print("ğŸš€ Voice Cloning Performance Benchmark")
    print("=" * 50)
    
    # Test texts of different lengths
    test_texts = [
        ("Short", "Hello world"),
        ("Medium", "This is a medium length text for testing voice cloning performance."),
        ("Long", "This is a much longer text that will take more time to process. It contains multiple sentences and should give us a better understanding of how the system performs with different input lengths. The goal is to measure the time it takes for the voice cloning process to complete."),
    ]
    
    # Test devices
    devices = ["auto"]
    if torch.cuda.is_available():
        devices.append("cuda")
    
    for device in devices:
        print(f"\nğŸ¯ Testing device: {device}")
        print("-" * 30)
        
        try:
            # Initialize voice cloner
            print(f"ğŸ”„ Initializing voice cloner on {device}...")
            start_time = time.time()
            cloner = VoiceCloner(device=device)
            init_time = time.time() - start_time
            print(f"âœ… Initialization time: {init_time:.2f}s")
            
            # Add a test voice sample (you need to provide an audio file)
            test_audio = "test_voice.wav"  # Change this to your test audio file
            if os.path.exists(test_audio):
                cloner.add_voice_sample("test_voice", test_audio, "Test voice")
                print(f"âœ… Added test voice sample")
                
                # Benchmark each text length
                for text_type, text in test_texts:
                    print(f"\nğŸ“ Testing {text_type} text ({len(text)} chars):")
                    print(f"Text: {text[:50]}{'...' if len(text) > 50 else ''}")
                    
                    # Warm up
                    print("ğŸ”¥ Warming up...")
                    try:
                        output_path = f"benchmark_{text_type}_{device}.wav"
                        start_time = time.time()
                        cloner.clone_voice(text, "test_voice", output_path)
                        warmup_time = time.time() - start_time
                        print(f"ğŸ”¥ Warmup time: {warmup_time:.2f}s")
                    except Exception as e:
                        print(f"âŒ Warmup failed: {e}")
                        continue
                    
                    # Actual benchmark
                    print("âš¡ Running benchmark...")
                    try:
                        start_time = time.time()
                        cloner.clone_voice(text, "test_voice", output_path)
                        benchmark_time = time.time() - start_time
                        
                        # Calculate performance metrics
                        chars_per_second = len(text) / benchmark_time
                        print(f"âš¡ Benchmark time: {benchmark_time:.2f}s")
                        print(f"ğŸ“Š Performance: {chars_per_second:.1f} chars/second")
                        
                        # Clean up
                        if os.path.exists(output_path):
                            os.remove(output_path)
                            
                    except Exception as e:
                        print(f"âŒ Benchmark failed: {e}")
                        
            else:
                print(f"âš ï¸ Test audio file not found: {test_audio}")
                print("ğŸ’¡ Please provide a test audio file to run benchmarks")
                
        except Exception as e:
            print(f"âŒ Failed to initialize voice cloner on {device}: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ Benchmark completed!")
    
    # Performance recommendations
    print("\nğŸ’¡ Performance Recommendations:")
    if torch.cuda.is_available():
        print("ğŸš€ Use GPU (CUDA) for best performance")
        print("âš¡ Enable half-precision (FP16) if memory allows")
    else:
        print("ğŸ’» CPU-only mode detected")
        print("ğŸ”§ Consider using a machine with GPU for better performance")
    
    print("ğŸ“ Shorter texts are faster to process")
    print("ğŸ¯ Use the optimized runner: python run_optimized.py")

if __name__ == "__main__":
    benchmark_voice_cloning() 