#!/usr/bin/env python3
"""
Setup Script for Voice Cloning Training
Chuáº©n bá»‹ mÃ´i trÆ°á»ng vÃ  cáº¥u trÃºc dá»¯ liá»‡u cho training
"""

import os
import shutil
from pathlib import Path


def setup_training_environment():
    """Thiáº¿t láº­p mÃ´i trÆ°á»ng training"""
    print("ğŸ”§ Setting up training environment...")
    
    # Táº¡o cáº¥u trÃºc thÆ° má»¥c
    directories = [
        "data",
        "data/audio",
        "data/audio/speaker1",
        "data/audio/speaker2",
        "models",
        "output",
        "checkpoints",
        "logs"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"ğŸ“ Created: {directory}")
    
    # Táº¡o file metadata máº«u
    create_sample_metadata()
    
    # Táº¡o config máº«u
    create_sample_config()
    
    # Táº¡o requirements.txt
    create_requirements()
    
    print("âœ… Training environment setup completed!")


def create_sample_metadata():
    """Táº¡o file metadata máº«u"""
    metadata_content = """filename|text
audio/speaker1/sample1.wav|Xin chÃ o, tÃ´i lÃ  ngÆ°á»i nÃ³i tiáº¿ng Viá»‡t
audio/speaker1/sample2.wav|HÃ´m nay trá»i Ä‘áº¹p quÃ¡
audio/speaker1/sample3.wav|Cáº£m Æ¡n báº¡n Ä‘Ã£ láº¯ng nghe
audio/speaker1/sample4.wav|ChÃºc báº¡n má»™t ngÃ y tá»‘t lÃ nh
audio/speaker1/sample5.wav|TÃ´i ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n
audio/speaker2/sample1.wav|Hello, I am an English speaker
audio/speaker2/sample2.wav|The weather is beautiful today
audio/speaker2/sample3.wav|Thank you for listening
audio/speaker2/sample4.wav|Have a great day
audio/speaker2/sample5.wav|I am happy to meet you"""
    
    with open("data/metadata.csv", "w", encoding="utf-8") as f:
        f.write(metadata_content)
    
    print("ğŸ“ Created sample metadata.csv")


def create_sample_config():
    """Táº¡o file config máº«u"""
    config_content = """{
    "model": "xtts",
    "run_name": "custom_voice_cloning",
    "run_description": "Custom Vietnamese Voice Cloning Model",
    "epochs": 1000,
    "batch_size": 4,
    "lr": 1e-4,
    "audio": {
        "sample_rate": 22050,
        "hop_length": 256,
        "win_length": 1024
    },
    "text": {
        "cleaner_name": "multilingual_cleaners"
    }
}"""
    
    with open("data/sample_config.json", "w", encoding="utf-8") as f:
        f.write(config_content)
    
    print("âš™ï¸ Created sample config.json")


def create_requirements():
    """Táº¡o file requirements.txt"""
    requirements_content = """# Voice Cloning Training Requirements
coqui-tts[all]>=0.14.0
torch>=1.13.0
torchaudio>=0.13.0
numpy>=1.21.0
scipy>=1.9.0
librosa>=0.9.2
soundfile>=0.12.1
matplotlib>=3.5.0
tqdm>=4.64.0
tensorboard>=2.10.0
wandb>=0.13.0
"""
    
    with open("requirements.txt", "w", encoding="utf-8") as f:
        f.write(requirements_content)
    
    print("ğŸ“¦ Created requirements.txt")


def create_training_guide():
    """Táº¡o hÆ°á»›ng dáº«n training"""
    guide_content = """# ğŸš€ Voice Cloning Training Guide

## ğŸ“‹ Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended)
- 8GB+ RAM
- 50GB+ free disk space

## ğŸ”§ Installation
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Verify installation
python -c "import TTS; print('âœ… TTS installed successfully')"
```

## ğŸ“ Data Preparation
1. **Audio Files**: Place your audio files in `data/audio/speaker1/`, `data/audio/speaker2/`, etc.
2. **Metadata**: Update `data/metadata.csv` with your audio files and corresponding text
3. **Format**: WAV, MP3, FLAC (22050Hz recommended)

## ğŸ¯ Training Steps

### Step 1: Prepare Data
```bash
python train_custom_model.py --mode prepare --audio_dir your_audio_folder
```

### Step 2: Start Training
```bash
python train_custom_model.py --mode train --config custom_xtts_config.json
```

### Step 3: Export Model
```bash
python train_custom_model.py --mode export --checkpoint path/to/checkpoint
```

## ğŸ“Š Training Parameters
- **Epochs**: 1000 (adjust based on data size)
- **Batch Size**: 4 (reduce if out of memory)
- **Learning Rate**: 1e-4 (adjust if training is unstable)
- **Save Checkpoints**: Every 1000 steps

## ğŸµ Audio Requirements
- **Duration**: 3-10 seconds per sample
- **Quality**: Clear, minimal noise
- **Quantity**: 50-100 samples per speaker minimum
- **Language**: Vietnamese + English (or your target languages)

## ğŸ” Monitoring Training
- **Tensorboard**: `tensorboard --logdir output/`
- **Checkpoints**: Saved in `checkpoints/` folder
- **Logs**: Training logs in `logs/` folder

## âš ï¸ Common Issues
1. **Out of Memory**: Reduce batch_size
2. **Training Slow**: Check GPU usage, reduce num_workers
3. **Poor Quality**: Increase training data, adjust learning rate

## ğŸ‰ After Training
1. Model saved in `models/` folder
2. Update `voice_cloner.py` to use custom model
3. Test with new voice samples

## ğŸ“ Support
- Check Coqui TTS documentation
- Monitor training logs for errors
- Adjust parameters based on your data
"""
    
    with open("TRAINING_GUIDE.md", "w", encoding="utf-8") as f:
        f.write(guide_content)
    
    print("ğŸ“š Created TRAINING_GUIDE.md")


def main():
    """Main function"""
    print("ğŸµ Voice Cloning Training Setup")
    print("=" * 40)
    
    setup_training_environment()
    create_training_guide()
    
    print("\nğŸ‰ Setup completed successfully!")
    print("\nğŸ“‹ Next steps:")
    print("1. Add your audio files to data/audio/ folders")
    print("2. Update data/metadata.csv with your data")
    print("3. Install dependencies: pip install -r requirements.txt")
    print("4. Start training: python train_custom_model.py --mode prepare")
    print("\nğŸ“š Read TRAINING_GUIDE.md for detailed instructions")


if __name__ == "__main__":
    main() 